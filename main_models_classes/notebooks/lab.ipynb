{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI   \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain   \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "# from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType   \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.llms import OpenAI   \n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "openai_api_key = \"sk-None-XS76dEz4IURDhsv2AJb9T3BlbkFJYoWnTsDhATqUPkspJY6n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Defintion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/.local/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(openai_api_key=openai_api_key , temperature=0.9, model=llm_model) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tell me about a brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"Tell me more about the brand {brand_name}. What are their popular products, target audience, and unique features? if it is not a fashion brand state that you are a fashion expert \")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tell me about a brand that offers a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"I'm looking to explore some fashion and dress brands that offer high-quality {product}. Could you provide a list of well-known and emerging brands that excel in this category? Please include information about their style, target audience, and any unique features or values that set them apart \"\n",
    ")\n",
    "\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt2)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what to were on occassion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = ChatPromptTemplate.from_template( \n",
    "    \"\"\"As a fashion expert, please recommend an outfit for the following situation: {situation}. Include details about the type of clothing, colors, accessories, and any additional styling tips to ensure the outfit is stylish and appropriate for the occasion.\"\"\" ) \n",
    "  \n",
    "chain_3 = LLMChain(llm=llm, prompt=prompt3)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\"], llm=llm)   \n",
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    max_tokens=150)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain to access csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/.local/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "2024-07-21 00:21:23.057106: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 00:21:23.097574: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-21 00:21:23.416663: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 00:21:24.301220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mohammad/.local/lib/python3.8/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n",
      "/home/mohammad/.local/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| ProductID | ProductName | ProductBrand | Gender | Price (INR) | NumImages | Description | PrimaryColor | Store |\n",
       "|-----------|-------------|--------------|--------|-------------|-----------|-------------|--------------|-------|\n",
       "| 1000795 | Being Human Clothing Navy Printed Casual Slim Shirt | Being Human | Men | 1079 | 6 | Navy blue printed casual shirt with spread collar, full button placket, two pockets, long sleeves, and curved hem | Navy | Store One |\n",
       "| 10000245 | Parx Men Green Printed Polo Collar T-shirt | Parx | Men | 629 | 5 | Green printed T-shirt with polo collar and short sleeves | Green | Store Three |\n",
       "| 10017899 | Parx Men Yellow & Off-White Slim Fit Checked Casual Shirt | Parx | Men | 647 | 4 | Yellow and off-white checked casual shirt with spread collar, long sleeves, button placket, curved hem, and one patch pocket | Yellow | Store One |\n",
       "| 10017831 | Parx Men Blue Slim Fit Printed Casual Shirt | Parx | Men | 779 | 5 | Blue printed casual shirt with spread collar, long sleeves, button placket, curved hem, and"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.llms import OpenAI\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "input_file = \"/home/mohammad/Downloads/stores.csv\"\n",
    "\n",
    "# Initialize the loader with the CSV file\n",
    "loader = CSVLoader(file_path=input_file)\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Create the vector store index with the embedding model\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embedding_model\n",
    ").from_loaders([loader])\n",
    "\n",
    "# Define the query\n",
    "query = \"Please list all your shirts with sun protection in a table in markdown and summarize each one.\"\n",
    "\n",
    "# Initialize the language model\n",
    "llm_replacement_model = OpenAI(temperature=0, model='gpt-3.5-turbo-instruct', openai_api_key=openai_api_key)\n",
    "\n",
    "# Perform the query\n",
    "response = index.query(query, llm=llm_replacement_model)\n",
    "\n",
    "# Display the response\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_request(request):\n",
    "    if \"brand\" in request:\n",
    "        return chain1.generate_response(request)\n",
    "    elif \"product\" in request:\n",
    "        return chain_2.generate_response(request)\n",
    "    elif \"situation\" in request:\n",
    "        return chain_3.generate_response(request)\n",
    "    else:\n",
    "        return agent.generate_response(request)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
